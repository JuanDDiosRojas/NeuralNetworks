{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6677f299",
   "metadata": {},
   "source": [
    "# Vamos a clasificar entre estrellas, cuásares y Galaxias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecc055f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from math import floor\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd06787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X,Y,porcent): #El porcentaje debe estar dado entre 0 y 1, será el porcentaje que mandará a entrenamiento\n",
    "    n=floor(porcent*len(X))\n",
    "    index=random.sample(range(len(X)),n)\n",
    "    X_learn=[]\n",
    "    Y_learn=[]\n",
    "    for i in index:\n",
    "        X_learn.append(X[i])\n",
    "        Y_learn.append(Y[i])\n",
    "    X_val=np.delete(X,index, axis=0)\n",
    "    Y_val=np.delete(Y,index, axis=0)\n",
    "    \n",
    "    X_learn=np.array(X_learn)\n",
    "    Y_learn=np.array(Y_learn)\n",
    "    \n",
    "    return X_learn,Y_learn,X_val,Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3699e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "estelares = pd.read_csv('https://raw.githubusercontent.com/igomezv/MACS_2021_ML_basics_neural_networks/main/data/Skyserver_SQL2_27_2018%206_51_39%20PM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d39dfb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run</th>\n",
       "      <th>rerun</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.531326</td>\n",
       "      <td>0.089693</td>\n",
       "      <td>19.47406</td>\n",
       "      <td>17.04240</td>\n",
       "      <td>15.94699</td>\n",
       "      <td>15.50342</td>\n",
       "      <td>15.22531</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.722360e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.598370</td>\n",
       "      <td>0.135285</td>\n",
       "      <td>18.66280</td>\n",
       "      <td>17.21449</td>\n",
       "      <td>16.67637</td>\n",
       "      <td>16.48922</td>\n",
       "      <td>16.39150</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.638140e+17</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>323</td>\n",
       "      <td>51615</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.680207</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>19.38298</td>\n",
       "      <td>18.19169</td>\n",
       "      <td>17.47428</td>\n",
       "      <td>17.08732</td>\n",
       "      <td>16.80125</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>268</td>\n",
       "      <td>3.232740e+17</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>287</td>\n",
       "      <td>52023</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.870529</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>17.76536</td>\n",
       "      <td>16.60272</td>\n",
       "      <td>16.16116</td>\n",
       "      <td>15.98233</td>\n",
       "      <td>15.90438</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.883288</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>17.55025</td>\n",
       "      <td>16.26342</td>\n",
       "      <td>16.43869</td>\n",
       "      <td>16.55492</td>\n",
       "      <td>16.61326</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>131.316413</td>\n",
       "      <td>51.539547</td>\n",
       "      <td>18.81777</td>\n",
       "      <td>17.47053</td>\n",
       "      <td>16.91508</td>\n",
       "      <td>16.68305</td>\n",
       "      <td>16.50570</td>\n",
       "      <td>1345</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "      <td>5.033450e+17</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.027583</td>\n",
       "      <td>447</td>\n",
       "      <td>51877</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>131.306083</td>\n",
       "      <td>51.671341</td>\n",
       "      <td>18.27255</td>\n",
       "      <td>17.43849</td>\n",
       "      <td>17.07692</td>\n",
       "      <td>16.71661</td>\n",
       "      <td>16.69897</td>\n",
       "      <td>1345</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>162</td>\n",
       "      <td>5.033400e+17</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.117772</td>\n",
       "      <td>447</td>\n",
       "      <td>51877</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>131.552562</td>\n",
       "      <td>51.666986</td>\n",
       "      <td>18.75818</td>\n",
       "      <td>17.77784</td>\n",
       "      <td>17.51872</td>\n",
       "      <td>17.43302</td>\n",
       "      <td>17.42048</td>\n",
       "      <td>1345</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>162</td>\n",
       "      <td>8.222620e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>7303</td>\n",
       "      <td>57013</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>131.477151</td>\n",
       "      <td>51.753068</td>\n",
       "      <td>18.88287</td>\n",
       "      <td>17.91068</td>\n",
       "      <td>17.53152</td>\n",
       "      <td>17.36284</td>\n",
       "      <td>17.13988</td>\n",
       "      <td>1345</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>5.033400e+17</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>447</td>\n",
       "      <td>51877</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>131.665012</td>\n",
       "      <td>51.805307</td>\n",
       "      <td>19.27586</td>\n",
       "      <td>17.37829</td>\n",
       "      <td>16.30542</td>\n",
       "      <td>15.83548</td>\n",
       "      <td>15.50588</td>\n",
       "      <td>1345</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>5.033410e+17</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>447</td>\n",
       "      <td>51877</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             objid          ra        dec         u         g         r  \\\n",
       "0     1.237650e+18  183.531326   0.089693  19.47406  17.04240  15.94699   \n",
       "1     1.237650e+18  183.598370   0.135285  18.66280  17.21449  16.67637   \n",
       "2     1.237650e+18  183.680207   0.126185  19.38298  18.19169  17.47428   \n",
       "3     1.237650e+18  183.870529   0.049911  17.76536  16.60272  16.16116   \n",
       "4     1.237650e+18  183.883288   0.102557  17.55025  16.26342  16.43869   \n",
       "...            ...         ...        ...       ...       ...       ...   \n",
       "9995  1.237650e+18  131.316413  51.539547  18.81777  17.47053  16.91508   \n",
       "9996  1.237650e+18  131.306083  51.671341  18.27255  17.43849  17.07692   \n",
       "9997  1.237650e+18  131.552562  51.666986  18.75818  17.77784  17.51872   \n",
       "9998  1.237650e+18  131.477151  51.753068  18.88287  17.91068  17.53152   \n",
       "9999  1.237650e+18  131.665012  51.805307  19.27586  17.37829  16.30542   \n",
       "\n",
       "             i         z   run  rerun  camcol  field     specobjid   class  \\\n",
       "0     15.50342  15.22531   752    301       4    267  3.722360e+18    STAR   \n",
       "1     16.48922  16.39150   752    301       4    267  3.638140e+17    STAR   \n",
       "2     17.08732  16.80125   752    301       4    268  3.232740e+17  GALAXY   \n",
       "3     15.98233  15.90438   752    301       4    269  3.722370e+18    STAR   \n",
       "4     16.55492  16.61326   752    301       4    269  3.722370e+18    STAR   \n",
       "...        ...       ...   ...    ...     ...    ...           ...     ...   \n",
       "9995  16.68305  16.50570  1345    301       3    161  5.033450e+17  GALAXY   \n",
       "9996  16.71661  16.69897  1345    301       3    162  5.033400e+17  GALAXY   \n",
       "9997  17.43302  17.42048  1345    301       3    162  8.222620e+18    STAR   \n",
       "9998  17.36284  17.13988  1345    301       3    163  5.033400e+17  GALAXY   \n",
       "9999  15.83548  15.50588  1345    301       3    163  5.033410e+17  GALAXY   \n",
       "\n",
       "      redshift  plate    mjd  fiberid  \n",
       "0    -0.000009   3306  54922      491  \n",
       "1    -0.000055    323  51615      541  \n",
       "2     0.123111    287  52023      513  \n",
       "3    -0.000111   3306  54922      510  \n",
       "4     0.000590   3306  54922      512  \n",
       "...        ...    ...    ...      ...  \n",
       "9995  0.027583    447  51877      246  \n",
       "9996  0.117772    447  51877      228  \n",
       "9997 -0.000402   7303  57013      622  \n",
       "9998  0.014019    447  51877      229  \n",
       "9999  0.118417    447  51877      233  \n",
       "\n",
       "[10000 rows x 18 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estelares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3054d501",
   "metadata": {},
   "source": [
    "###### Vamos a usar sólo los atributos u,g,r,i,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "005618f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.47406</td>\n",
       "      <td>17.04240</td>\n",
       "      <td>15.94699</td>\n",
       "      <td>15.50342</td>\n",
       "      <td>15.22531</td>\n",
       "      <td>STAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.66280</td>\n",
       "      <td>17.21449</td>\n",
       "      <td>16.67637</td>\n",
       "      <td>16.48922</td>\n",
       "      <td>16.39150</td>\n",
       "      <td>STAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.38298</td>\n",
       "      <td>18.19169</td>\n",
       "      <td>17.47428</td>\n",
       "      <td>17.08732</td>\n",
       "      <td>16.80125</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.76536</td>\n",
       "      <td>16.60272</td>\n",
       "      <td>16.16116</td>\n",
       "      <td>15.98233</td>\n",
       "      <td>15.90438</td>\n",
       "      <td>STAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.55025</td>\n",
       "      <td>16.26342</td>\n",
       "      <td>16.43869</td>\n",
       "      <td>16.55492</td>\n",
       "      <td>16.61326</td>\n",
       "      <td>STAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>18.81777</td>\n",
       "      <td>17.47053</td>\n",
       "      <td>16.91508</td>\n",
       "      <td>16.68305</td>\n",
       "      <td>16.50570</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>18.27255</td>\n",
       "      <td>17.43849</td>\n",
       "      <td>17.07692</td>\n",
       "      <td>16.71661</td>\n",
       "      <td>16.69897</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>18.75818</td>\n",
       "      <td>17.77784</td>\n",
       "      <td>17.51872</td>\n",
       "      <td>17.43302</td>\n",
       "      <td>17.42048</td>\n",
       "      <td>STAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>18.88287</td>\n",
       "      <td>17.91068</td>\n",
       "      <td>17.53152</td>\n",
       "      <td>17.36284</td>\n",
       "      <td>17.13988</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19.27586</td>\n",
       "      <td>17.37829</td>\n",
       "      <td>16.30542</td>\n",
       "      <td>15.83548</td>\n",
       "      <td>15.50588</td>\n",
       "      <td>GALAXY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             u         g         r         i         z   class\n",
       "0     19.47406  17.04240  15.94699  15.50342  15.22531    STAR\n",
       "1     18.66280  17.21449  16.67637  16.48922  16.39150    STAR\n",
       "2     19.38298  18.19169  17.47428  17.08732  16.80125  GALAXY\n",
       "3     17.76536  16.60272  16.16116  15.98233  15.90438    STAR\n",
       "4     17.55025  16.26342  16.43869  16.55492  16.61326    STAR\n",
       "...        ...       ...       ...       ...       ...     ...\n",
       "9995  18.81777  17.47053  16.91508  16.68305  16.50570  GALAXY\n",
       "9996  18.27255  17.43849  17.07692  16.71661  16.69897  GALAXY\n",
       "9997  18.75818  17.77784  17.51872  17.43302  17.42048    STAR\n",
       "9998  18.88287  17.91068  17.53152  17.36284  17.13988  GALAXY\n",
       "9999  19.27586  17.37829  16.30542  15.83548  15.50588  GALAXY\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos=estelares.loc[:,['u','g','r','i','z','class']];datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e17f4",
   "metadata": {},
   "source": [
    "##### Haremos los vectores one-hot como sigue:\n",
    "[star, galaxy, qso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2aeddb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases=[]\n",
    "for i in datos['class']:\n",
    "    if i=='STAR': clases.append([1,0,0])\n",
    "    if i=='GALAXY': clases.append([0,1,0])\n",
    "    if i=='QSO': clases.append([0,0,1])\n",
    "        \n",
    "clases=np.array(clases);clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f01a01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Así nuestros conjuntos serán \n",
    "X=estelares.loc[:,['u','g','r','i','z']];X\n",
    "#y Y=clases\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef8deb",
   "metadata": {},
   "source": [
    "#### Aquí tenemos nuestro conjunto de datos X, clases\n",
    "#### Vamos a separarlos en un conjunto para el modelo y en un conjunto para hacer predcciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "26396f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modelo,Y_modelo,X_pred,Y_pred=split(X,clases,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1b15c7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "55024b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 1.0747 - accuracy: 0.4198 - val_loss: 1.0251 - val_accuracy: 0.3994\n",
      "Epoch 2/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.0109 - accuracy: 0.4860 - val_loss: 0.9802 - val_accuracy: 0.5119\n",
      "Epoch 3/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9723 - accuracy: 0.5058 - val_loss: 0.9530 - val_accuracy: 0.5119\n",
      "Epoch 4/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9456 - accuracy: 0.5007 - val_loss: 0.9377 - val_accuracy: 0.5119\n",
      "Epoch 5/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9299 - accuracy: 0.4996 - val_loss: 0.9301 - val_accuracy: 0.5119\n",
      "Epoch 6/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9220 - accuracy: 0.5055 - val_loss: 0.9265 - val_accuracy: 0.5119\n",
      "Epoch 7/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9234 - accuracy: 0.4963 - val_loss: 0.9249 - val_accuracy: 0.5119\n",
      "Epoch 8/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9226 - accuracy: 0.4954 - val_loss: 0.9241 - val_accuracy: 0.5119\n",
      "Epoch 9/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9174 - accuracy: 0.4919 - val_loss: 0.9238 - val_accuracy: 0.5119\n",
      "Epoch 10/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9156 - accuracy: 0.5046 - val_loss: 0.9239 - val_accuracy: 0.5119\n",
      "Epoch 11/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9110 - accuracy: 0.5073 - val_loss: 0.9239 - val_accuracy: 0.5119\n",
      "Epoch 12/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9147 - accuracy: 0.5073 - val_loss: 0.9240 - val_accuracy: 0.5119\n",
      "Epoch 13/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9193 - accuracy: 0.4980 - val_loss: 0.9240 - val_accuracy: 0.5119\n",
      "Epoch 14/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9157 - accuracy: 0.5022 - val_loss: 0.9239 - val_accuracy: 0.5119\n",
      "Epoch 15/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9183 - accuracy: 0.4930 - val_loss: 0.9238 - val_accuracy: 0.5119\n",
      "Epoch 16/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9165 - accuracy: 0.4927 - val_loss: 0.9239 - val_accuracy: 0.5119\n",
      "Epoch 17/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9196 - accuracy: 0.4931 - val_loss: 0.9238 - val_accuracy: 0.5119\n",
      "Epoch 18/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9244 - accuracy: 0.4982 - val_loss: 0.9239 - val_accuracy: 0.5119\n",
      "Epoch 19/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9202 - accuracy: 0.5050 - val_loss: 0.9240 - val_accuracy: 0.5119\n",
      "Epoch 20/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9260 - accuracy: 0.4910 - val_loss: 0.9237 - val_accuracy: 0.5119\n",
      "Epoch 21/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9102 - accuracy: 0.5030 - val_loss: 0.9238 - val_accuracy: 0.5119\n",
      "Epoch 22/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9224 - accuracy: 0.5018 - val_loss: 0.9239 - val_accuracy: 0.5119\n",
      "Epoch 23/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9122 - accuracy: 0.5012 - val_loss: 0.9238 - val_accuracy: 0.5119\n",
      "Epoch 24/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9267 - accuracy: 0.4958 - val_loss: 0.9236 - val_accuracy: 0.5119\n",
      "Epoch 25/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9278 - accuracy: 0.4917 - val_loss: 0.9237 - val_accuracy: 0.5119\n",
      "Epoch 26/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9133 - accuracy: 0.5085 - val_loss: 0.9237 - val_accuracy: 0.5119\n",
      "Epoch 27/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9211 - accuracy: 0.5084 - val_loss: 0.9237 - val_accuracy: 0.5119\n",
      "Epoch 28/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9292 - accuracy: 0.4875 - val_loss: 0.9235 - val_accuracy: 0.5119\n",
      "Epoch 29/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9149 - accuracy: 0.4986 - val_loss: 0.9235 - val_accuracy: 0.5119\n",
      "Epoch 30/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9194 - accuracy: 0.4910 - val_loss: 0.9234 - val_accuracy: 0.5119\n",
      "Epoch 31/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9183 - accuracy: 0.4985 - val_loss: 0.9235 - val_accuracy: 0.5119\n",
      "Epoch 32/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9179 - accuracy: 0.4952 - val_loss: 0.9234 - val_accuracy: 0.5119\n",
      "Epoch 33/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9120 - accuracy: 0.5042 - val_loss: 0.9234 - val_accuracy: 0.5119\n",
      "Epoch 34/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9156 - accuracy: 0.4962 - val_loss: 0.9233 - val_accuracy: 0.5119\n",
      "Epoch 35/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9126 - accuracy: 0.5035 - val_loss: 0.9234 - val_accuracy: 0.5119\n",
      "Epoch 36/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9166 - accuracy: 0.5102 - val_loss: 0.9234 - val_accuracy: 0.5119\n",
      "Epoch 37/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9265 - accuracy: 0.4888 - val_loss: 0.9231 - val_accuracy: 0.5119\n",
      "Epoch 38/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9232 - accuracy: 0.4956 - val_loss: 0.9230 - val_accuracy: 0.5119\n",
      "Epoch 39/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9215 - accuracy: 0.4999 - val_loss: 0.9230 - val_accuracy: 0.5119\n",
      "Epoch 40/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9172 - accuracy: 0.4914 - val_loss: 0.9229 - val_accuracy: 0.5119\n",
      "Epoch 41/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9168 - accuracy: 0.5013 - val_loss: 0.9229 - val_accuracy: 0.5119\n",
      "Epoch 42/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9155 - accuracy: 0.4926 - val_loss: 0.9229 - val_accuracy: 0.5119\n",
      "Epoch 43/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9212 - accuracy: 0.4869 - val_loss: 0.9226 - val_accuracy: 0.5119\n",
      "Epoch 44/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9173 - accuracy: 0.4968 - val_loss: 0.9227 - val_accuracy: 0.5119\n",
      "Epoch 45/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9131 - accuracy: 0.5069 - val_loss: 0.9229 - val_accuracy: 0.5119\n",
      "Epoch 46/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9215 - accuracy: 0.5032 - val_loss: 0.9228 - val_accuracy: 0.5119\n",
      "Epoch 47/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9249 - accuracy: 0.4937 - val_loss: 0.9227 - val_accuracy: 0.5119\n",
      "Epoch 48/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9154 - accuracy: 0.4907 - val_loss: 0.9224 - val_accuracy: 0.5119\n",
      "Epoch 49/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9117 - accuracy: 0.4986 - val_loss: 0.9221 - val_accuracy: 0.5119\n",
      "Epoch 50/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9210 - accuracy: 0.4967 - val_loss: 0.9222 - val_accuracy: 0.5119\n",
      "Epoch 51/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9223 - accuracy: 0.4945 - val_loss: 0.9221 - val_accuracy: 0.5119\n",
      "Epoch 52/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9223 - accuracy: 0.4867 - val_loss: 0.9220 - val_accuracy: 0.5119\n",
      "Epoch 53/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9167 - accuracy: 0.5029 - val_loss: 0.9220 - val_accuracy: 0.5119\n",
      "Epoch 54/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9162 - accuracy: 0.4927 - val_loss: 0.9219 - val_accuracy: 0.5119\n",
      "Epoch 55/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9101 - accuracy: 0.4947 - val_loss: 0.9217 - val_accuracy: 0.5119\n",
      "Epoch 56/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9145 - accuracy: 0.4980 - val_loss: 0.9217 - val_accuracy: 0.5119\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9102 - accuracy: 0.5102 - val_loss: 0.9219 - val_accuracy: 0.5119\n",
      "Epoch 58/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9149 - accuracy: 0.4995 - val_loss: 0.9217 - val_accuracy: 0.5119\n",
      "Epoch 59/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9161 - accuracy: 0.4924 - val_loss: 0.9214 - val_accuracy: 0.5119\n",
      "Epoch 60/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9167 - accuracy: 0.4805 - val_loss: 0.9211 - val_accuracy: 0.5119\n",
      "Epoch 61/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9133 - accuracy: 0.5040 - val_loss: 0.9213 - val_accuracy: 0.5119\n",
      "Epoch 62/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9178 - accuracy: 0.4789 - val_loss: 0.9210 - val_accuracy: 0.5119\n",
      "Epoch 63/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9209 - accuracy: 0.4786 - val_loss: 0.9207 - val_accuracy: 0.5119\n",
      "Epoch 64/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9101 - accuracy: 0.5010 - val_loss: 0.9209 - val_accuracy: 0.5119\n",
      "Epoch 65/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9134 - accuracy: 0.4891 - val_loss: 0.9208 - val_accuracy: 0.5119\n",
      "Epoch 66/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9136 - accuracy: 0.4941 - val_loss: 0.9208 - val_accuracy: 0.5119\n",
      "Epoch 67/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9218 - accuracy: 0.4909 - val_loss: 0.9206 - val_accuracy: 0.5119\n",
      "Epoch 68/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9297 - accuracy: 0.4825 - val_loss: 0.9203 - val_accuracy: 0.5119\n",
      "Epoch 69/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9160 - accuracy: 0.5016 - val_loss: 0.9203 - val_accuracy: 0.5119\n",
      "Epoch 70/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9126 - accuracy: 0.5012 - val_loss: 0.9203 - val_accuracy: 0.5119\n",
      "Epoch 71/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9182 - accuracy: 0.4898 - val_loss: 0.9201 - val_accuracy: 0.5119\n",
      "Epoch 72/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.4926 - val_loss: 0.9199 - val_accuracy: 0.5119\n",
      "Epoch 73/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9197 - accuracy: 0.4915 - val_loss: 0.9198 - val_accuracy: 0.5119\n",
      "Epoch 74/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9071 - accuracy: 0.5058 - val_loss: 0.9199 - val_accuracy: 0.5119\n",
      "Epoch 75/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9050 - accuracy: 0.5079 - val_loss: 0.9198 - val_accuracy: 0.5119\n",
      "Epoch 76/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 0.4953 - val_loss: 0.9196 - val_accuracy: 0.5119\n",
      "Epoch 77/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9211 - accuracy: 0.4940 - val_loss: 0.9193 - val_accuracy: 0.5119\n",
      "Epoch 78/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9129 - accuracy: 0.5022 - val_loss: 0.9193 - val_accuracy: 0.5119\n",
      "Epoch 79/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9118 - accuracy: 0.4990 - val_loss: 0.9192 - val_accuracy: 0.5119\n",
      "Epoch 80/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9130 - accuracy: 0.4913 - val_loss: 0.9189 - val_accuracy: 0.5119\n",
      "Epoch 81/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9088 - accuracy: 0.5018 - val_loss: 0.9190 - val_accuracy: 0.5119\n",
      "Epoch 82/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8991 - accuracy: 0.5028 - val_loss: 0.9188 - val_accuracy: 0.5119\n",
      "Epoch 83/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9111 - accuracy: 0.4964 - val_loss: 0.9186 - val_accuracy: 0.5119\n",
      "Epoch 84/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9123 - accuracy: 0.5000 - val_loss: 0.9184 - val_accuracy: 0.5119\n",
      "Epoch 85/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9055 - accuracy: 0.5035 - val_loss: 0.9182 - val_accuracy: 0.5119\n",
      "Epoch 86/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9140 - accuracy: 0.4956 - val_loss: 0.9181 - val_accuracy: 0.5119\n",
      "Epoch 87/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9124 - accuracy: 0.4970 - val_loss: 0.9179 - val_accuracy: 0.5119\n",
      "Epoch 88/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9117 - accuracy: 0.5008 - val_loss: 0.9178 - val_accuracy: 0.5119\n",
      "Epoch 89/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9145 - accuracy: 0.5024 - val_loss: 0.9176 - val_accuracy: 0.5119\n",
      "Epoch 90/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9076 - accuracy: 0.4981 - val_loss: 0.9174 - val_accuracy: 0.5119\n",
      "Epoch 91/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9150 - accuracy: 0.4900 - val_loss: 0.9171 - val_accuracy: 0.5119\n",
      "Epoch 92/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9180 - accuracy: 0.4997 - val_loss: 0.9171 - val_accuracy: 0.5119\n",
      "Epoch 93/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9269 - accuracy: 0.4924 - val_loss: 0.9168 - val_accuracy: 0.5119\n",
      "Epoch 94/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9214 - accuracy: 0.4977 - val_loss: 0.9167 - val_accuracy: 0.5119\n",
      "Epoch 95/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9070 - accuracy: 0.4992 - val_loss: 0.9163 - val_accuracy: 0.5119\n",
      "Epoch 96/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9094 - accuracy: 0.4937 - val_loss: 0.9161 - val_accuracy: 0.5119\n",
      "Epoch 97/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9137 - accuracy: 0.4969 - val_loss: 0.9159 - val_accuracy: 0.5119\n",
      "Epoch 98/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9056 - accuracy: 0.5012 - val_loss: 0.9159 - val_accuracy: 0.5119\n",
      "Epoch 99/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9102 - accuracy: 0.5016 - val_loss: 0.9156 - val_accuracy: 0.5119\n",
      "Epoch 100/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9080 - accuracy: 0.5009 - val_loss: 0.9153 - val_accuracy: 0.5119\n",
      "Epoch 101/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9194 - accuracy: 0.4914 - val_loss: 0.9150 - val_accuracy: 0.5119\n",
      "Epoch 102/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9046 - accuracy: 0.4965 - val_loss: 0.9147 - val_accuracy: 0.5119\n",
      "Epoch 103/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9197 - accuracy: 0.4914 - val_loss: 0.9145 - val_accuracy: 0.5119\n",
      "Epoch 104/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9132 - accuracy: 0.4924 - val_loss: 0.9142 - val_accuracy: 0.5119\n",
      "Epoch 105/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9189 - accuracy: 0.4958 - val_loss: 0.9141 - val_accuracy: 0.5119\n",
      "Epoch 106/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9194 - accuracy: 0.4940 - val_loss: 0.9138 - val_accuracy: 0.5119\n",
      "Epoch 107/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8930 - accuracy: 0.5111 - val_loss: 0.9136 - val_accuracy: 0.5119\n",
      "Epoch 108/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9105 - accuracy: 0.4941 - val_loss: 0.9131 - val_accuracy: 0.5119\n",
      "Epoch 109/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9094 - accuracy: 0.4954 - val_loss: 0.9129 - val_accuracy: 0.5119\n",
      "Epoch 110/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9114 - accuracy: 0.4988 - val_loss: 0.9126 - val_accuracy: 0.5119\n",
      "Epoch 111/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9066 - accuracy: 0.4964 - val_loss: 0.9123 - val_accuracy: 0.5125\n",
      "Epoch 112/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9082 - accuracy: 0.4989 - val_loss: 0.9122 - val_accuracy: 0.5125\n",
      "Epoch 113/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5004 - val_loss: 0.9117 - val_accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9040 - accuracy: 0.4957 - val_loss: 0.9115 - val_accuracy: 0.5125\n",
      "Epoch 115/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9057 - accuracy: 0.5019 - val_loss: 0.9111 - val_accuracy: 0.5125\n",
      "Epoch 116/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9119 - accuracy: 0.4910 - val_loss: 0.9107 - val_accuracy: 0.5125\n",
      "Epoch 117/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9000 - accuracy: 0.5021 - val_loss: 0.9104 - val_accuracy: 0.5125\n",
      "Epoch 118/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9152 - accuracy: 0.4812 - val_loss: 0.9098 - val_accuracy: 0.5125\n",
      "Epoch 119/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9079 - accuracy: 0.4902 - val_loss: 0.9095 - val_accuracy: 0.5125\n",
      "Epoch 120/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9020 - accuracy: 0.4999 - val_loss: 0.9091 - val_accuracy: 0.5125\n",
      "Epoch 121/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9009 - accuracy: 0.4953 - val_loss: 0.9088 - val_accuracy: 0.5138\n",
      "Epoch 122/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8971 - accuracy: 0.5037 - val_loss: 0.9084 - val_accuracy: 0.5138\n",
      "Epoch 123/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8897 - accuracy: 0.5149 - val_loss: 0.9083 - val_accuracy: 0.5181\n",
      "Epoch 124/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9108 - accuracy: 0.4967 - val_loss: 0.9077 - val_accuracy: 0.5163\n",
      "Epoch 125/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8975 - accuracy: 0.5032 - val_loss: 0.9073 - val_accuracy: 0.5169\n",
      "Epoch 126/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9117 - accuracy: 0.4983 - val_loss: 0.9069 - val_accuracy: 0.5219\n",
      "Epoch 127/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8973 - accuracy: 0.5028 - val_loss: 0.9064 - val_accuracy: 0.5219\n",
      "Epoch 128/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8997 - accuracy: 0.5100 - val_loss: 0.9061 - val_accuracy: 0.5256\n",
      "Epoch 129/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8994 - accuracy: 0.5162 - val_loss: 0.9058 - val_accuracy: 0.5269\n",
      "Epoch 130/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8986 - accuracy: 0.5143 - val_loss: 0.9050 - val_accuracy: 0.5256\n",
      "Epoch 131/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8959 - accuracy: 0.5022 - val_loss: 0.9043 - val_accuracy: 0.5250\n",
      "Epoch 132/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9002 - accuracy: 0.5102 - val_loss: 0.9040 - val_accuracy: 0.5269\n",
      "Epoch 133/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8982 - accuracy: 0.5036 - val_loss: 0.9034 - val_accuracy: 0.5269\n",
      "Epoch 134/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8965 - accuracy: 0.5062 - val_loss: 0.9026 - val_accuracy: 0.5256\n",
      "Epoch 135/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9010 - accuracy: 0.5140 - val_loss: 0.9022 - val_accuracy: 0.5269\n",
      "Epoch 136/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5106 - val_loss: 0.9016 - val_accuracy: 0.5269\n",
      "Epoch 137/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.8986 - accuracy: 0.5023 - val_loss: 0.9010 - val_accuracy: 0.5269\n",
      "Epoch 138/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.8973 - accuracy: 0.5081 - val_loss: 0.9004 - val_accuracy: 0.5269\n",
      "Epoch 139/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.8957 - accuracy: 0.5171 - val_loss: 0.9001 - val_accuracy: 0.5294\n",
      "Epoch 140/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.8970 - accuracy: 0.5129 - val_loss: 0.8990 - val_accuracy: 0.5275\n",
      "Epoch 141/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.9022 - accuracy: 0.5092 - val_loss: 0.8986 - val_accuracy: 0.5281\n",
      "Epoch 142/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 0.5118 - val_loss: 0.8979 - val_accuracy: 0.5294\n",
      "Epoch 143/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8960 - accuracy: 0.5035 - val_loss: 0.8971 - val_accuracy: 0.5275\n",
      "Epoch 144/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9010 - accuracy: 0.5093 - val_loss: 0.8964 - val_accuracy: 0.5294\n",
      "Epoch 145/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8799 - accuracy: 0.5165 - val_loss: 0.8960 - val_accuracy: 0.5325\n",
      "Epoch 146/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8814 - accuracy: 0.5140 - val_loss: 0.8951 - val_accuracy: 0.5325\n",
      "Epoch 147/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8892 - accuracy: 0.5052 - val_loss: 0.8942 - val_accuracy: 0.5319\n",
      "Epoch 148/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8855 - accuracy: 0.5126 - val_loss: 0.8934 - val_accuracy: 0.5325\n",
      "Epoch 149/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8893 - accuracy: 0.5051 - val_loss: 0.8927 - val_accuracy: 0.5331\n",
      "Epoch 150/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8858 - accuracy: 0.5092 - val_loss: 0.8919 - val_accuracy: 0.5344\n",
      "Epoch 151/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8815 - accuracy: 0.5163 - val_loss: 0.8911 - val_accuracy: 0.5350\n",
      "Epoch 152/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8931 - accuracy: 0.5079 - val_loss: 0.8900 - val_accuracy: 0.5331\n",
      "Epoch 153/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8887 - accuracy: 0.5171 - val_loss: 0.8896 - val_accuracy: 0.5387\n",
      "Epoch 154/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8880 - accuracy: 0.5149 - val_loss: 0.8885 - val_accuracy: 0.5375\n",
      "Epoch 155/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8738 - accuracy: 0.5280 - val_loss: 0.8879 - val_accuracy: 0.5450\n",
      "Epoch 156/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8872 - accuracy: 0.5213 - val_loss: 0.8865 - val_accuracy: 0.5375\n",
      "Epoch 157/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8784 - accuracy: 0.5227 - val_loss: 0.8857 - val_accuracy: 0.5412\n",
      "Epoch 158/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8873 - accuracy: 0.5230 - val_loss: 0.8848 - val_accuracy: 0.5425\n",
      "Epoch 159/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8696 - accuracy: 0.5343 - val_loss: 0.8837 - val_accuracy: 0.5425\n",
      "Epoch 160/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8828 - accuracy: 0.5275 - val_loss: 0.8824 - val_accuracy: 0.5394\n",
      "Epoch 161/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8772 - accuracy: 0.5213 - val_loss: 0.8815 - val_accuracy: 0.5462\n",
      "Epoch 162/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8800 - accuracy: 0.5314 - val_loss: 0.8803 - val_accuracy: 0.5431\n",
      "Epoch 163/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8879 - accuracy: 0.5250 - val_loss: 0.8792 - val_accuracy: 0.5469\n",
      "Epoch 164/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8720 - accuracy: 0.5357 - val_loss: 0.8781 - val_accuracy: 0.5494\n",
      "Epoch 165/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8705 - accuracy: 0.5437 - val_loss: 0.8769 - val_accuracy: 0.5481\n",
      "Epoch 166/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8764 - accuracy: 0.5423 - val_loss: 0.8759 - val_accuracy: 0.5612\n",
      "Epoch 167/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8793 - accuracy: 0.5485 - val_loss: 0.8746 - val_accuracy: 0.5650\n",
      "Epoch 168/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8783 - accuracy: 0.5635 - val_loss: 0.8733 - val_accuracy: 0.5625\n",
      "Epoch 169/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8749 - accuracy: 0.5522 - val_loss: 0.8722 - val_accuracy: 0.5956\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8607 - accuracy: 0.5784 - val_loss: 0.8710 - val_accuracy: 0.6037\n",
      "Epoch 171/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8702 - accuracy: 0.5831 - val_loss: 0.8696 - val_accuracy: 0.5987\n",
      "Epoch 172/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8620 - accuracy: 0.5780 - val_loss: 0.8686 - val_accuracy: 0.6162\n",
      "Epoch 173/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8707 - accuracy: 0.5874 - val_loss: 0.8672 - val_accuracy: 0.6156\n",
      "Epoch 174/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8635 - accuracy: 0.5913 - val_loss: 0.8656 - val_accuracy: 0.6156\n",
      "Epoch 175/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8596 - accuracy: 0.5973 - val_loss: 0.8641 - val_accuracy: 0.6044\n",
      "Epoch 176/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8556 - accuracy: 0.5968 - val_loss: 0.8628 - val_accuracy: 0.6025\n",
      "Epoch 177/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8742 - accuracy: 0.5950 - val_loss: 0.8613 - val_accuracy: 0.6031\n",
      "Epoch 178/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8619 - accuracy: 0.5921 - val_loss: 0.8600 - val_accuracy: 0.6162\n",
      "Epoch 179/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8509 - accuracy: 0.6004 - val_loss: 0.8586 - val_accuracy: 0.6263\n",
      "Epoch 180/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8551 - accuracy: 0.6078 - val_loss: 0.8576 - val_accuracy: 0.6475\n",
      "Epoch 181/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8583 - accuracy: 0.6135 - val_loss: 0.8555 - val_accuracy: 0.6288\n",
      "Epoch 182/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8535 - accuracy: 0.6149 - val_loss: 0.8541 - val_accuracy: 0.6269\n",
      "Epoch 183/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8597 - accuracy: 0.6111 - val_loss: 0.8526 - val_accuracy: 0.6313\n",
      "Epoch 184/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8465 - accuracy: 0.6178 - val_loss: 0.8514 - val_accuracy: 0.6425\n",
      "Epoch 185/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8510 - accuracy: 0.6177 - val_loss: 0.8500 - val_accuracy: 0.6506\n",
      "Epoch 186/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8573 - accuracy: 0.6236 - val_loss: 0.8480 - val_accuracy: 0.6356\n",
      "Epoch 187/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8547 - accuracy: 0.6139 - val_loss: 0.8467 - val_accuracy: 0.6494\n",
      "Epoch 188/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8483 - accuracy: 0.6273 - val_loss: 0.8452 - val_accuracy: 0.6525\n",
      "Epoch 189/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8455 - accuracy: 0.6241 - val_loss: 0.8437 - val_accuracy: 0.6525\n",
      "Epoch 190/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8356 - accuracy: 0.6328 - val_loss: 0.8426 - val_accuracy: 0.6575\n",
      "Epoch 191/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8454 - accuracy: 0.6405 - val_loss: 0.8406 - val_accuracy: 0.6562\n",
      "Epoch 192/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8438 - accuracy: 0.6460 - val_loss: 0.8386 - val_accuracy: 0.6531\n",
      "Epoch 193/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8242 - accuracy: 0.6388 - val_loss: 0.8371 - val_accuracy: 0.6562\n",
      "Epoch 194/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8325 - accuracy: 0.6501 - val_loss: 0.8351 - val_accuracy: 0.6531\n",
      "Epoch 195/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8289 - accuracy: 0.6435 - val_loss: 0.8337 - val_accuracy: 0.6544\n",
      "Epoch 196/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8400 - accuracy: 0.6399 - val_loss: 0.8320 - val_accuracy: 0.6575\n",
      "Epoch 197/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8370 - accuracy: 0.6369 - val_loss: 0.8298 - val_accuracy: 0.6494\n",
      "Epoch 198/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8328 - accuracy: 0.6470 - val_loss: 0.8286 - val_accuracy: 0.6587\n",
      "Epoch 199/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8201 - accuracy: 0.6523 - val_loss: 0.8269 - val_accuracy: 0.6612\n",
      "Epoch 200/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8277 - accuracy: 0.6489 - val_loss: 0.8247 - val_accuracy: 0.6538\n",
      "Epoch 201/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8241 - accuracy: 0.6485 - val_loss: 0.8233 - val_accuracy: 0.6619\n",
      "Epoch 202/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.8184 - accuracy: 0.6492 - val_loss: 0.8210 - val_accuracy: 0.6562\n",
      "Epoch 203/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.8177 - accuracy: 0.6533 - val_loss: 0.8201 - val_accuracy: 0.6625\n",
      "Epoch 204/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.8286 - accuracy: 0.6463 - val_loss: 0.8175 - val_accuracy: 0.6569\n",
      "Epoch 205/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8163 - accuracy: 0.6509 - val_loss: 0.8159 - val_accuracy: 0.6612\n",
      "Epoch 206/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8190 - accuracy: 0.6448 - val_loss: 0.8138 - val_accuracy: 0.6587\n",
      "Epoch 207/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8172 - accuracy: 0.6498 - val_loss: 0.8120 - val_accuracy: 0.6619\n",
      "Epoch 208/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8145 - accuracy: 0.6556 - val_loss: 0.8101 - val_accuracy: 0.6644\n",
      "Epoch 209/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8195 - accuracy: 0.6451 - val_loss: 0.8082 - val_accuracy: 0.6644\n",
      "Epoch 210/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8119 - accuracy: 0.6468 - val_loss: 0.8063 - val_accuracy: 0.6637\n",
      "Epoch 211/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8011 - accuracy: 0.6567 - val_loss: 0.8043 - val_accuracy: 0.6637\n",
      "Epoch 212/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8001 - accuracy: 0.6578 - val_loss: 0.8023 - val_accuracy: 0.6625\n",
      "Epoch 213/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7907 - accuracy: 0.6609 - val_loss: 0.8007 - val_accuracy: 0.6650\n",
      "Epoch 214/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8034 - accuracy: 0.6524 - val_loss: 0.7991 - val_accuracy: 0.6656\n",
      "Epoch 215/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8023 - accuracy: 0.6544 - val_loss: 0.7972 - val_accuracy: 0.6656\n",
      "Epoch 216/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8065 - accuracy: 0.6468 - val_loss: 0.7954 - val_accuracy: 0.6662\n",
      "Epoch 217/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7946 - accuracy: 0.6553 - val_loss: 0.7934 - val_accuracy: 0.6656\n",
      "Epoch 218/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7929 - accuracy: 0.6586 - val_loss: 0.7911 - val_accuracy: 0.6637\n",
      "Epoch 219/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7902 - accuracy: 0.6541 - val_loss: 0.7895 - val_accuracy: 0.6650\n",
      "Epoch 220/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7981 - accuracy: 0.6466 - val_loss: 0.7872 - val_accuracy: 0.6644\n",
      "Epoch 221/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7897 - accuracy: 0.6460 - val_loss: 0.7855 - val_accuracy: 0.6662\n",
      "Epoch 222/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7805 - accuracy: 0.6631 - val_loss: 0.7837 - val_accuracy: 0.6669\n",
      "Epoch 223/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7858 - accuracy: 0.6575 - val_loss: 0.7824 - val_accuracy: 0.6694\n",
      "Epoch 224/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7769 - accuracy: 0.6681 - val_loss: 0.7810 - val_accuracy: 0.6719\n",
      "Epoch 225/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7804 - accuracy: 0.6577 - val_loss: 0.7783 - val_accuracy: 0.6669\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7853 - accuracy: 0.6567 - val_loss: 0.7767 - val_accuracy: 0.6681\n",
      "Epoch 227/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7725 - accuracy: 0.6611 - val_loss: 0.7753 - val_accuracy: 0.6706\n",
      "Epoch 228/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7871 - accuracy: 0.6566 - val_loss: 0.7731 - val_accuracy: 0.6700\n",
      "Epoch 229/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7733 - accuracy: 0.6536 - val_loss: 0.7712 - val_accuracy: 0.6700\n",
      "Epoch 230/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7727 - accuracy: 0.6573 - val_loss: 0.7695 - val_accuracy: 0.6706\n",
      "Epoch 231/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7725 - accuracy: 0.6610 - val_loss: 0.7675 - val_accuracy: 0.6687\n",
      "Epoch 232/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7720 - accuracy: 0.6568 - val_loss: 0.7655 - val_accuracy: 0.6656\n",
      "Epoch 233/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7752 - accuracy: 0.6537 - val_loss: 0.7643 - val_accuracy: 0.6725\n",
      "Epoch 234/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7620 - accuracy: 0.6603 - val_loss: 0.7634 - val_accuracy: 0.6694\n",
      "Epoch 235/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7639 - accuracy: 0.6664 - val_loss: 0.7606 - val_accuracy: 0.6687\n",
      "Epoch 236/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7618 - accuracy: 0.6586 - val_loss: 0.7592 - val_accuracy: 0.6719\n",
      "Epoch 237/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7595 - accuracy: 0.6644 - val_loss: 0.7577 - val_accuracy: 0.6700\n",
      "Epoch 238/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7611 - accuracy: 0.6554 - val_loss: 0.7557 - val_accuracy: 0.6712\n",
      "Epoch 239/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7562 - accuracy: 0.6663 - val_loss: 0.7540 - val_accuracy: 0.6719\n",
      "Epoch 240/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7529 - accuracy: 0.6603 - val_loss: 0.7530 - val_accuracy: 0.6687\n",
      "Epoch 241/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7550 - accuracy: 0.6697 - val_loss: 0.7512 - val_accuracy: 0.6675\n",
      "Epoch 242/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7565 - accuracy: 0.6544 - val_loss: 0.7494 - val_accuracy: 0.6700\n",
      "Epoch 243/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7611 - accuracy: 0.6512 - val_loss: 0.7481 - val_accuracy: 0.6681\n",
      "Epoch 244/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.6610 - val_loss: 0.7461 - val_accuracy: 0.6706\n",
      "Epoch 245/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7533 - accuracy: 0.6590 - val_loss: 0.7453 - val_accuracy: 0.6700\n",
      "Epoch 246/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7445 - accuracy: 0.6662 - val_loss: 0.7432 - val_accuracy: 0.6675\n",
      "Epoch 247/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7402 - accuracy: 0.6689 - val_loss: 0.7420 - val_accuracy: 0.6700\n",
      "Epoch 248/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.6636 - val_loss: 0.7403 - val_accuracy: 0.6706\n",
      "Epoch 249/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.6573 - val_loss: 0.7390 - val_accuracy: 0.6681\n",
      "Epoch 250/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7391 - accuracy: 0.6597 - val_loss: 0.7368 - val_accuracy: 0.6687\n",
      "Epoch 251/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.6665 - val_loss: 0.7359 - val_accuracy: 0.6687\n",
      "Epoch 252/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.6677 - val_loss: 0.7339 - val_accuracy: 0.6706\n",
      "Epoch 253/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.6708 - val_loss: 0.7320 - val_accuracy: 0.6700\n",
      "Epoch 254/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.6722 - val_loss: 0.7312 - val_accuracy: 0.6700\n",
      "Epoch 255/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.6608 - val_loss: 0.7292 - val_accuracy: 0.6681\n",
      "Epoch 256/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.6653 - val_loss: 0.7277 - val_accuracy: 0.6694\n",
      "Epoch 257/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6729 - val_loss: 0.7265 - val_accuracy: 0.6694\n",
      "Epoch 258/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.6626 - val_loss: 0.7249 - val_accuracy: 0.6687\n",
      "Epoch 259/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7390 - accuracy: 0.6590 - val_loss: 0.7235 - val_accuracy: 0.6675\n",
      "Epoch 260/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6598 - val_loss: 0.7220 - val_accuracy: 0.6712\n",
      "Epoch 261/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.6556 - val_loss: 0.7211 - val_accuracy: 0.6706\n",
      "Epoch 262/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6631 - val_loss: 0.7195 - val_accuracy: 0.6694\n",
      "Epoch 263/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7132 - accuracy: 0.6715 - val_loss: 0.7185 - val_accuracy: 0.6712\n",
      "Epoch 264/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6674 - val_loss: 0.7168 - val_accuracy: 0.6700\n",
      "Epoch 265/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.6681 - val_loss: 0.7162 - val_accuracy: 0.6694\n",
      "Epoch 266/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6654 - val_loss: 0.7146 - val_accuracy: 0.6712\n",
      "Epoch 267/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6637 - val_loss: 0.7143 - val_accuracy: 0.6706\n",
      "Epoch 268/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7076 - accuracy: 0.6681 - val_loss: 0.7125 - val_accuracy: 0.6687\n",
      "Epoch 269/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.6698 - val_loss: 0.7112 - val_accuracy: 0.6712\n",
      "Epoch 270/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.6710 - val_loss: 0.7105 - val_accuracy: 0.6694\n",
      "Epoch 271/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.6670 - val_loss: 0.7089 - val_accuracy: 0.6712\n",
      "Epoch 272/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.6734 - val_loss: 0.7079 - val_accuracy: 0.6687\n",
      "Epoch 273/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.6647 - val_loss: 0.7064 - val_accuracy: 0.6700\n",
      "Epoch 274/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.6691 - val_loss: 0.7055 - val_accuracy: 0.6706\n",
      "Epoch 275/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.6743 - val_loss: 0.7043 - val_accuracy: 0.6694\n",
      "Epoch 276/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.6685 - val_loss: 0.7039 - val_accuracy: 0.6719\n",
      "Epoch 277/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.6621 - val_loss: 0.7022 - val_accuracy: 0.6694\n",
      "Epoch 278/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7122 - accuracy: 0.6548 - val_loss: 0.7007 - val_accuracy: 0.6706\n",
      "Epoch 279/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.6678 - val_loss: 0.6997 - val_accuracy: 0.6712\n",
      "Epoch 280/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6513 - val_loss: 0.6988 - val_accuracy: 0.6700\n",
      "Epoch 281/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.6724 - val_loss: 0.6977 - val_accuracy: 0.6719\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.6631 - val_loss: 0.6970 - val_accuracy: 0.6694\n",
      "Epoch 283/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.6643 - val_loss: 0.6961 - val_accuracy: 0.6719\n",
      "Epoch 284/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.6680 - val_loss: 0.6953 - val_accuracy: 0.6731\n",
      "Epoch 285/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.6687 - val_loss: 0.6935 - val_accuracy: 0.6706\n",
      "Epoch 286/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.6637 - val_loss: 0.6932 - val_accuracy: 0.6706\n",
      "Epoch 287/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.6565 - val_loss: 0.6919 - val_accuracy: 0.6700\n",
      "Epoch 288/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7043 - accuracy: 0.6602 - val_loss: 0.6908 - val_accuracy: 0.6719\n",
      "Epoch 289/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.6729 - val_loss: 0.6902 - val_accuracy: 0.6700\n",
      "Epoch 290/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.6669 - val_loss: 0.6900 - val_accuracy: 0.6712\n",
      "Epoch 291/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.6604 - val_loss: 0.6882 - val_accuracy: 0.6700\n",
      "Epoch 292/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.6731 - val_loss: 0.6873 - val_accuracy: 0.6706\n",
      "Epoch 293/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.6607 - val_loss: 0.6867 - val_accuracy: 0.6731\n",
      "Epoch 294/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.6577 - val_loss: 0.6857 - val_accuracy: 0.6719\n",
      "Epoch 295/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.6788 - val_loss: 0.6851 - val_accuracy: 0.6731\n",
      "Epoch 296/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.6692 - val_loss: 0.6835 - val_accuracy: 0.6700\n",
      "Epoch 297/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.6578 - val_loss: 0.6833 - val_accuracy: 0.6725\n",
      "Epoch 298/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.6713 - val_loss: 0.6821 - val_accuracy: 0.6712\n",
      "Epoch 299/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.6774 - val_loss: 0.6810 - val_accuracy: 0.6719\n",
      "Epoch 300/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.6669 - val_loss: 0.6806 - val_accuracy: 0.6719\n",
      "Epoch 301/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.6770 - val_loss: 0.6803 - val_accuracy: 0.6719\n",
      "Epoch 302/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.6618 - val_loss: 0.6793 - val_accuracy: 0.6725\n",
      "Epoch 303/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.6704 - val_loss: 0.6780 - val_accuracy: 0.6706\n",
      "Epoch 304/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.6604 - val_loss: 0.6778 - val_accuracy: 0.6725\n",
      "Epoch 305/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.6646 - val_loss: 0.6765 - val_accuracy: 0.6719\n",
      "Epoch 306/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.6731 - val_loss: 0.6764 - val_accuracy: 0.6712\n",
      "Epoch 307/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.6650 - val_loss: 0.6748 - val_accuracy: 0.6706\n",
      "Epoch 308/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.6590 - val_loss: 0.6748 - val_accuracy: 0.6706\n",
      "Epoch 309/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.6631 - val_loss: 0.6743 - val_accuracy: 0.6687\n",
      "Epoch 310/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.6685 - val_loss: 0.6732 - val_accuracy: 0.6700\n",
      "Epoch 311/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.6598 - val_loss: 0.6724 - val_accuracy: 0.6681\n",
      "Epoch 312/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.6634 - val_loss: 0.6717 - val_accuracy: 0.6675\n",
      "Epoch 313/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6746 - accuracy: 0.6707 - val_loss: 0.6716 - val_accuracy: 0.6681\n",
      "Epoch 314/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.6544 - val_loss: 0.6702 - val_accuracy: 0.6662\n",
      "Epoch 315/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.6642 - val_loss: 0.6716 - val_accuracy: 0.6700\n",
      "Epoch 316/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.6683 - val_loss: 0.6696 - val_accuracy: 0.6681\n",
      "Epoch 317/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6769 - accuracy: 0.6532 - val_loss: 0.6684 - val_accuracy: 0.6650\n",
      "Epoch 318/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.6737 - val_loss: 0.6681 - val_accuracy: 0.6669\n",
      "Epoch 319/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.6638 - val_loss: 0.6671 - val_accuracy: 0.6656\n",
      "Epoch 320/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.6689 - val_loss: 0.6665 - val_accuracy: 0.6637\n",
      "Epoch 321/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6779 - accuracy: 0.6618 - val_loss: 0.6669 - val_accuracy: 0.6619\n",
      "Epoch 322/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.6627 - val_loss: 0.6652 - val_accuracy: 0.6625\n",
      "Epoch 323/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.6601 - val_loss: 0.6647 - val_accuracy: 0.6637\n",
      "Epoch 324/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.6570 - val_loss: 0.6646 - val_accuracy: 0.6644\n",
      "Epoch 325/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6724 - val_loss: 0.6641 - val_accuracy: 0.6625\n",
      "Epoch 326/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.6627 - val_loss: 0.6637 - val_accuracy: 0.6606\n",
      "Epoch 327/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.6575 - val_loss: 0.6630 - val_accuracy: 0.6619\n",
      "Epoch 328/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6625 - accuracy: 0.6669 - val_loss: 0.6621 - val_accuracy: 0.6612\n",
      "Epoch 329/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.6548 - val_loss: 0.6619 - val_accuracy: 0.6606\n",
      "Epoch 330/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.6575 - val_loss: 0.6613 - val_accuracy: 0.6606\n",
      "Epoch 331/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.6505 - val_loss: 0.6606 - val_accuracy: 0.6606\n",
      "Epoch 332/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.6548 - val_loss: 0.6601 - val_accuracy: 0.6606\n",
      "Epoch 333/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6646 - val_loss: 0.6604 - val_accuracy: 0.6575\n",
      "Epoch 334/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6508 - val_loss: 0.6593 - val_accuracy: 0.6600\n",
      "Epoch 335/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.6632 - val_loss: 0.6587 - val_accuracy: 0.6594\n",
      "Epoch 336/500\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6678 - val_loss: 0.6583 - val_accuracy: 0.6594\n",
      "Epoch 337/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.6551 - val_loss: 0.6578 - val_accuracy: 0.6594\n",
      "Epoch 338/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.6628 - val_loss: 0.6574 - val_accuracy: 0.6587\n",
      "Epoch 339/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6622 - val_loss: 0.6568 - val_accuracy: 0.6594\n",
      "Epoch 340/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6606 - val_loss: 0.6566 - val_accuracy: 0.6581\n",
      "Epoch 341/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6596 - val_loss: 0.6564 - val_accuracy: 0.6594\n",
      "Epoch 342/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6693 - val_loss: 0.6560 - val_accuracy: 0.6600\n",
      "Epoch 343/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.6544 - val_loss: 0.6555 - val_accuracy: 0.6594\n",
      "Epoch 344/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6548 - val_loss: 0.6553 - val_accuracy: 0.6562\n",
      "Epoch 345/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6632 - val_loss: 0.6546 - val_accuracy: 0.6581\n",
      "Epoch 346/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.6579 - val_loss: 0.6542 - val_accuracy: 0.6581\n",
      "Epoch 347/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6684 - val_loss: 0.6536 - val_accuracy: 0.6600\n",
      "Epoch 348/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.6500 - val_loss: 0.6534 - val_accuracy: 0.6581\n",
      "Epoch 349/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6574 - val_loss: 0.6530 - val_accuracy: 0.6581\n",
      "Epoch 350/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6590 - val_loss: 0.6534 - val_accuracy: 0.6587\n",
      "Epoch 351/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.6527 - val_loss: 0.6521 - val_accuracy: 0.6600\n",
      "Epoch 352/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.6535 - val_loss: 0.6528 - val_accuracy: 0.6594\n",
      "Epoch 353/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6677 - val_loss: 0.6519 - val_accuracy: 0.6587\n",
      "Epoch 354/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.6442 - val_loss: 0.6514 - val_accuracy: 0.6587\n",
      "Epoch 355/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6544 - val_loss: 0.6519 - val_accuracy: 0.6587\n",
      "Epoch 356/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6623 - val_loss: 0.6515 - val_accuracy: 0.6594\n",
      "Epoch 357/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6595 - val_loss: 0.6506 - val_accuracy: 0.6569\n",
      "Epoch 358/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6628 - val_loss: 0.6509 - val_accuracy: 0.6587\n",
      "Epoch 359/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.6706 - val_loss: 0.6495 - val_accuracy: 0.6594\n",
      "Epoch 360/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.6518 - val_loss: 0.6497 - val_accuracy: 0.6562\n",
      "Epoch 361/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6553 - val_loss: 0.6499 - val_accuracy: 0.6581\n",
      "Epoch 362/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6613 - val_loss: 0.6488 - val_accuracy: 0.6594\n",
      "Epoch 363/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6601 - val_loss: 0.6487 - val_accuracy: 0.6569\n",
      "Epoch 364/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6656 - val_loss: 0.6482 - val_accuracy: 0.6581\n",
      "Epoch 365/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6671 - val_loss: 0.6486 - val_accuracy: 0.6594\n",
      "Epoch 366/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6621 - val_loss: 0.6476 - val_accuracy: 0.6575\n",
      "Epoch 367/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6578 - val_loss: 0.6476 - val_accuracy: 0.6594\n",
      "Epoch 368/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.6706 - val_loss: 0.6470 - val_accuracy: 0.6600\n",
      "Epoch 369/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.6581 - val_loss: 0.6469 - val_accuracy: 0.6600\n",
      "Epoch 370/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.6589 - val_loss: 0.6464 - val_accuracy: 0.6600\n",
      "Epoch 371/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6634 - val_loss: 0.6464 - val_accuracy: 0.6612\n",
      "Epoch 372/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6396 - accuracy: 0.6681 - val_loss: 0.6464 - val_accuracy: 0.6619\n",
      "Epoch 373/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6619 - val_loss: 0.6461 - val_accuracy: 0.6631\n",
      "Epoch 374/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6615 - val_loss: 0.6456 - val_accuracy: 0.6625\n",
      "Epoch 375/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6592 - val_loss: 0.6460 - val_accuracy: 0.6625\n",
      "Epoch 376/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6628 - val_loss: 0.6457 - val_accuracy: 0.6625\n",
      "Epoch 377/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6641 - val_loss: 0.6454 - val_accuracy: 0.6619\n",
      "Epoch 378/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.6649 - val_loss: 0.6455 - val_accuracy: 0.6625\n",
      "Epoch 379/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6530 - val_loss: 0.6446 - val_accuracy: 0.6619\n",
      "Epoch 380/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6586 - val_loss: 0.6446 - val_accuracy: 0.6612\n",
      "Epoch 381/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6569 - val_loss: 0.6444 - val_accuracy: 0.6612\n",
      "Epoch 382/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6606 - val_loss: 0.6445 - val_accuracy: 0.6619\n",
      "Epoch 383/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6621 - val_loss: 0.6435 - val_accuracy: 0.6619\n",
      "Epoch 384/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6604 - val_loss: 0.6435 - val_accuracy: 0.6606\n",
      "Epoch 385/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6671 - val_loss: 0.6441 - val_accuracy: 0.6644\n",
      "Epoch 386/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6671 - val_loss: 0.6431 - val_accuracy: 0.6606\n",
      "Epoch 387/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6599 - val_loss: 0.6429 - val_accuracy: 0.6612\n",
      "Epoch 388/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6629 - val_loss: 0.6433 - val_accuracy: 0.6631\n",
      "Epoch 389/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6685 - val_loss: 0.6426 - val_accuracy: 0.6619\n",
      "Epoch 390/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6682 - val_loss: 0.6424 - val_accuracy: 0.6619\n",
      "Epoch 391/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6627 - val_loss: 0.6420 - val_accuracy: 0.6637\n",
      "Epoch 392/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6679 - val_loss: 0.6420 - val_accuracy: 0.6619\n",
      "Epoch 393/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.6663 - val_loss: 0.6425 - val_accuracy: 0.6706\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.6814 - val_loss: 0.6415 - val_accuracy: 0.6619\n",
      "Epoch 395/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6689 - val_loss: 0.6416 - val_accuracy: 0.6656\n",
      "Epoch 396/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6849 - val_loss: 0.6432 - val_accuracy: 0.6762\n",
      "Epoch 397/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6696 - val_loss: 0.6412 - val_accuracy: 0.6662\n",
      "Epoch 398/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6721 - val_loss: 0.6412 - val_accuracy: 0.6700\n",
      "Epoch 399/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6311 - accuracy: 0.6852 - val_loss: 0.6416 - val_accuracy: 0.6712\n",
      "Epoch 400/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6380 - accuracy: 0.6773 - val_loss: 0.6405 - val_accuracy: 0.6700\n",
      "Epoch 401/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.6650 - val_loss: 0.6412 - val_accuracy: 0.6719\n",
      "Epoch 402/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6678 - val_loss: 0.6402 - val_accuracy: 0.6656\n",
      "Epoch 403/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.6718 - val_loss: 0.6400 - val_accuracy: 0.6662\n",
      "Epoch 404/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.6730 - val_loss: 0.6405 - val_accuracy: 0.6725\n",
      "Epoch 405/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.6757 - val_loss: 0.6399 - val_accuracy: 0.6712\n",
      "Epoch 406/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6728 - val_loss: 0.6399 - val_accuracy: 0.6712\n",
      "Epoch 407/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6774 - val_loss: 0.6398 - val_accuracy: 0.6725\n",
      "Epoch 408/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6782 - val_loss: 0.6396 - val_accuracy: 0.6712\n",
      "Epoch 409/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.6792 - val_loss: 0.6397 - val_accuracy: 0.6725\n",
      "Epoch 410/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6838 - val_loss: 0.6395 - val_accuracy: 0.6719\n",
      "Epoch 411/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.6812 - val_loss: 0.6399 - val_accuracy: 0.6744\n",
      "Epoch 412/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6838 - val_loss: 0.6402 - val_accuracy: 0.6787\n",
      "Epoch 413/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.6778 - val_loss: 0.6391 - val_accuracy: 0.6719\n",
      "Epoch 414/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.6846 - val_loss: 0.6394 - val_accuracy: 0.6769\n",
      "Epoch 415/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6263 - accuracy: 0.6956 - val_loss: 0.6387 - val_accuracy: 0.6731\n",
      "Epoch 416/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.6835 - val_loss: 0.6383 - val_accuracy: 0.6700\n",
      "Epoch 417/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6711 - val_loss: 0.6383 - val_accuracy: 0.6694\n",
      "Epoch 418/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6427 - accuracy: 0.6745 - val_loss: 0.6384 - val_accuracy: 0.6750\n",
      "Epoch 419/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6823 - val_loss: 0.6380 - val_accuracy: 0.6712\n",
      "Epoch 420/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6746 - val_loss: 0.6391 - val_accuracy: 0.6800\n",
      "Epoch 421/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6715 - val_loss: 0.6381 - val_accuracy: 0.6756\n",
      "Epoch 422/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6778 - val_loss: 0.6380 - val_accuracy: 0.6744\n",
      "Epoch 423/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.6730 - val_loss: 0.6383 - val_accuracy: 0.6787\n",
      "Epoch 424/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6852 - val_loss: 0.6388 - val_accuracy: 0.6812\n",
      "Epoch 425/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6259 - accuracy: 0.6867 - val_loss: 0.6377 - val_accuracy: 0.6787\n",
      "Epoch 426/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.6793 - val_loss: 0.6377 - val_accuracy: 0.6794\n",
      "Epoch 427/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6750 - val_loss: 0.6373 - val_accuracy: 0.6706\n",
      "Epoch 428/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6742 - val_loss: 0.6371 - val_accuracy: 0.6694\n",
      "Epoch 429/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.6839 - val_loss: 0.6370 - val_accuracy: 0.6756\n",
      "Epoch 430/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6765 - val_loss: 0.6374 - val_accuracy: 0.6794\n",
      "Epoch 431/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6913 - val_loss: 0.6368 - val_accuracy: 0.6737\n",
      "Epoch 432/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6853 - val_loss: 0.6371 - val_accuracy: 0.6800\n",
      "Epoch 433/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6851 - val_loss: 0.6367 - val_accuracy: 0.6806\n",
      "Epoch 434/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6832 - val_loss: 0.6369 - val_accuracy: 0.6812\n",
      "Epoch 435/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.6985 - val_loss: 0.6372 - val_accuracy: 0.6800\n",
      "Epoch 436/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.6853 - val_loss: 0.6364 - val_accuracy: 0.6800\n",
      "Epoch 437/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6396 - accuracy: 0.6831 - val_loss: 0.6363 - val_accuracy: 0.6762\n",
      "Epoch 438/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.6902 - val_loss: 0.6365 - val_accuracy: 0.6800\n",
      "Epoch 439/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6865 - val_loss: 0.6366 - val_accuracy: 0.6800\n",
      "Epoch 440/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.6865 - val_loss: 0.6376 - val_accuracy: 0.6913\n",
      "Epoch 441/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6813 - val_loss: 0.6361 - val_accuracy: 0.6806\n",
      "Epoch 442/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6789 - val_loss: 0.6360 - val_accuracy: 0.6744\n",
      "Epoch 443/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.6834 - val_loss: 0.6360 - val_accuracy: 0.6806\n",
      "Epoch 444/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6787 - val_loss: 0.6362 - val_accuracy: 0.6800\n",
      "Epoch 445/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.6830 - val_loss: 0.6364 - val_accuracy: 0.6812\n",
      "Epoch 446/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6793 - val_loss: 0.6358 - val_accuracy: 0.6806\n",
      "Epoch 447/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.6905 - val_loss: 0.6355 - val_accuracy: 0.6819\n",
      "Epoch 448/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6897 - val_loss: 0.6353 - val_accuracy: 0.6800\n",
      "Epoch 449/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.6873 - val_loss: 0.6356 - val_accuracy: 0.6800\n",
      "Epoch 450/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.6968 - val_loss: 0.6353 - val_accuracy: 0.6812\n",
      "Epoch 451/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6815 - val_loss: 0.6367 - val_accuracy: 0.6925\n",
      "Epoch 452/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6359 - accuracy: 0.6905 - val_loss: 0.6351 - val_accuracy: 0.6806\n",
      "Epoch 453/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.6859 - val_loss: 0.6357 - val_accuracy: 0.6862\n",
      "Epoch 454/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.6911 - val_loss: 0.6350 - val_accuracy: 0.6825\n",
      "Epoch 455/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.6920 - val_loss: 0.6350 - val_accuracy: 0.6819\n",
      "Epoch 456/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6877 - val_loss: 0.6348 - val_accuracy: 0.6806\n",
      "Epoch 457/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.6884 - val_loss: 0.6349 - val_accuracy: 0.6819\n",
      "Epoch 458/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.6949 - val_loss: 0.6347 - val_accuracy: 0.6819\n",
      "Epoch 459/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.6820 - val_loss: 0.6350 - val_accuracy: 0.6850\n",
      "Epoch 460/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.6886 - val_loss: 0.6358 - val_accuracy: 0.6944\n",
      "Epoch 461/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.6996 - val_loss: 0.6345 - val_accuracy: 0.6819\n",
      "Epoch 462/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.6814 - val_loss: 0.6352 - val_accuracy: 0.6888\n",
      "Epoch 463/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6921 - val_loss: 0.6347 - val_accuracy: 0.6862\n",
      "Epoch 464/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6897 - val_loss: 0.6345 - val_accuracy: 0.6850\n",
      "Epoch 465/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6882 - val_loss: 0.6348 - val_accuracy: 0.6875\n",
      "Epoch 466/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.7010 - val_loss: 0.6344 - val_accuracy: 0.6862\n",
      "Epoch 467/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.6924 - val_loss: 0.6342 - val_accuracy: 0.6862\n",
      "Epoch 468/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6834 - val_loss: 0.6339 - val_accuracy: 0.6825\n",
      "Epoch 469/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.6897 - val_loss: 0.6339 - val_accuracy: 0.6850\n",
      "Epoch 470/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.6961 - val_loss: 0.6339 - val_accuracy: 0.6869\n",
      "Epoch 471/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6845 - val_loss: 0.6338 - val_accuracy: 0.6862\n",
      "Epoch 472/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6980 - val_loss: 0.6341 - val_accuracy: 0.6900\n",
      "Epoch 473/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6934 - val_loss: 0.6345 - val_accuracy: 0.6931\n",
      "Epoch 474/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6955 - val_loss: 0.6348 - val_accuracy: 0.6988\n",
      "Epoch 475/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6346 - accuracy: 0.6986 - val_loss: 0.6338 - val_accuracy: 0.6862\n",
      "Epoch 476/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.6915 - val_loss: 0.6338 - val_accuracy: 0.6862\n",
      "Epoch 477/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.6839 - val_loss: 0.6335 - val_accuracy: 0.6862\n",
      "Epoch 478/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6229 - accuracy: 0.6964 - val_loss: 0.6334 - val_accuracy: 0.6869\n",
      "Epoch 479/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6925 - val_loss: 0.6335 - val_accuracy: 0.6875\n",
      "Epoch 480/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.6974 - val_loss: 0.6334 - val_accuracy: 0.6869\n",
      "Epoch 481/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6357 - accuracy: 0.6886 - val_loss: 0.6333 - val_accuracy: 0.6881\n",
      "Epoch 482/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6969 - val_loss: 0.6366 - val_accuracy: 0.7063\n",
      "Epoch 483/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6977 - val_loss: 0.6335 - val_accuracy: 0.6900\n",
      "Epoch 484/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.6962 - val_loss: 0.6336 - val_accuracy: 0.6913\n",
      "Epoch 485/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6955 - val_loss: 0.6330 - val_accuracy: 0.6837\n",
      "Epoch 486/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.7018 - val_loss: 0.6331 - val_accuracy: 0.6900\n",
      "Epoch 487/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6976 - val_loss: 0.6335 - val_accuracy: 0.6950\n",
      "Epoch 488/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6905 - val_loss: 0.6330 - val_accuracy: 0.6900\n",
      "Epoch 489/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.6959 - val_loss: 0.6331 - val_accuracy: 0.6906\n",
      "Epoch 490/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6268 - accuracy: 0.7016 - val_loss: 0.6328 - val_accuracy: 0.6875\n",
      "Epoch 491/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.6999 - val_loss: 0.6329 - val_accuracy: 0.6875\n",
      "Epoch 492/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6901 - val_loss: 0.6331 - val_accuracy: 0.6944\n",
      "Epoch 493/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6813 - val_loss: 0.6331 - val_accuracy: 0.6938\n",
      "Epoch 494/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.7008 - val_loss: 0.6327 - val_accuracy: 0.6888\n",
      "Epoch 495/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.7078 - val_loss: 0.6331 - val_accuracy: 0.6956\n",
      "Epoch 496/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.6996 - val_loss: 0.6326 - val_accuracy: 0.6906\n",
      "Epoch 497/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.6849 - val_loss: 0.6344 - val_accuracy: 0.7044\n",
      "Epoch 498/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.6889 - val_loss: 0.6333 - val_accuracy: 0.7013\n",
      "Epoch 499/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.6999 - val_loss: 0.6324 - val_accuracy: 0.6862\n",
      "Epoch 500/500\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6947 - val_loss: 0.6330 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Error durante el entrenamiento')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodos=70\n",
    "split_size=0.8\n",
    "taza=0.00001\n",
    "epocas=500\n",
    "\n",
    "#Separamos los datos en validación y entrenamiento\n",
    "X_learn,Y_learn,X_val,Y_val=split(X_modelo,Y_modelo,split_size)\n",
    "\n",
    "#Armamos el modelo con estructura 'Sequential'\n",
    "model=models.Sequential()\n",
    "\n",
    "#la primer capa recibe un numero solamente, usaremos sigmoide como función de activación para la capa oculta\n",
    "capa1=layers.Dense(nodos, input_shape=(5,),use_bias=1,activation='sigmoid')\n",
    "capa2=layers.Dense(nodos,use_bias=1,activation='sigmoid')\n",
    "capa3=layers.Dense(nodos,use_bias=1,activation='sigmoid')\n",
    "capa4=layers.Dense(nodos,use_bias=1,activation='sigmoid')\n",
    "#para la capa de salida usamos Id como activación\n",
    "salida=layers.Dense(3,use_bias=1,activation='softmax')\n",
    "\n",
    "model.add(capa1)\n",
    "model.add(capa2)\n",
    "model.add(capa3)\n",
    "model.add(capa4)\n",
    "model.add(salida)\n",
    "\n",
    "\n",
    "loss_fn = losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizers.RMSprop(\n",
    "    learning_rate=taza),\n",
    "loss=losses.categorical_crossentropy,\n",
    "metrics=['accuracy'])\n",
    "\n",
    "#por último traemos los datos de entrenamiento y los procesamos con 'fit()'\n",
    "history=model.fit(X_learn,Y_learn,validation_data=(X_val, Y_val),epochs=epocas,shuffle=True)\n",
    "#batch_size=512)\n",
    "\n",
    "error=history.history['loss']\n",
    "exac=history.history['val_loss']\n",
    "\n",
    "epochs=np.arange(0,len(error))\n",
    "plt.plot(epochs,error,label='Error entrenamiento',color='darkblue')\n",
    "plt.plot(epochs,exac,label='Error Validación',color='r')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Error durante el entrenamiento',color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82fd723",
   "metadata": {},
   "source": [
    "##### Ahora vamos a probar con el conjunto que reservamos para hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0023ee3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de aciertos fue del 3.4805 porciento\n"
     ]
    }
   ],
   "source": [
    "predicciones=model.predict(X)\n",
    "#Ahora tomamos la máxima probabilidad de cada sample y lo llevamos a la forma one-hot\n",
    "#for j in predicciones:\n",
    "    #j[np.argmax(j)]=1\n",
    "    #j[j<1]=0\n",
    "#Y por último veamos cuántos acertó comparando predicciones con Y_pred\n",
    "s=0\n",
    "for i in range(len(clases)):\n",
    "    if np.argmax(predicciones[i])==np.argmax(clases[i]):\n",
    "        s=s+1\n",
    "print(\"El porcentaje de aciertos fue del\",s/len(Y_pred),\"porciento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3a534852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.1073040e-02, 9.2869073e-01, 2.3626658e-04],\n",
       "       [4.6191630e-01, 5.2714545e-01, 1.0938249e-02],\n",
       "       [3.3120459e-01, 6.6416788e-01, 4.6274327e-03],\n",
       "       ...,\n",
       "       [7.3039299e-01, 1.2776364e-01, 1.4184339e-01],\n",
       "       [6.8968797e-01, 2.5466686e-01, 5.5645216e-02],\n",
       "       [9.6123680e-02, 9.0348238e-01, 3.9401450e-04]], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5db27a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1c6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
